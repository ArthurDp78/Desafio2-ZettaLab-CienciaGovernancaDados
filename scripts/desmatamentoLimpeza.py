import os
import re
import glob
import sys
import argparse
import logging
from pathlib import Path

# Bibliotecas de manipulaÃ§Ã£o de dados
import pandas as pd
import geopandas as gpd

# Bibliotecas de visualizaÃ§Ã£o
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression
import numpy as np


# Caminho da base original
caminho = "base/desmatamento/desmatamento_por_estado.csv"

# UFs da AmazÃ´nia Legal
AMAZONIA_LEGAL_UFS = {"AC", "AM", "AP", "MA", "MT", "PA", "RO", "RR", "TO"}

# Arquivo de saÃ­da
output = Path("limpos/desmatamento/desmatamento_2012-2021.csv")
output.parent.mkdir(parents=True, exist_ok=True)

print("Iniciando processamento do desmatamento...")

# 1ï¸âƒ£ Ler a base (tratando BOM/encoding)
try:
    df = pd.read_csv(caminho, encoding='utf-8-sig', low_memory=False)
except Exception:
    df = pd.read_csv(caminho, encoding='latin-1', low_memory=False)
print("âœ… Base carregada com sucesso!", f"(linhas={len(df)})")

# 2ï¸âƒ£ Detectar e normalizar colunas esperadas com fallback
col_candidates = {
    'state': ['state', 'estado', 'uf', 'UF', 'State'],
    'year': ['year', 'ano', 'Year', 'YEAR'],
    'area': ['area_km', 'area', 'area_km2', 'area__km']
}

col_map = {}
for target, candidates in col_candidates.items():
    for c in candidates:
        if c in df.columns:
            col_map[c] = target
            break

if not any(v == 'state' for v in col_map.values()) and 'state' not in df.columns and 'estado' not in df.columns:
    # try common column names
    if 'UF' in df.columns:
        df = df.rename(columns={'UF': 'state'})
        col_map['state'] = 'state'

# Apply renames to standard names
rename_map = {}
if any(k for k,v in col_map.items() if v == 'state'):
    src = next(k for k,v in col_map.items() if v == 'state')
    rename_map[src] = 'UF'
if any(k for k,v in col_map.items() if v == 'year'):
    src = next(k for k,v in col_map.items() if v == 'year')
    rename_map[src] = 'ano'
if any(k for k,v in col_map.items() if v == 'area'):
    src = next(k for k,v in col_map.items() if v == 'area')
    rename_map[src] = 'area_km'

if not rename_map:
    raise KeyError('Colunas esperadas nÃ£o encontradas. Procure por state/estado/UF, year/ano e area_km/area.')

df = df.rename(columns=rename_map)
print('ðŸ”¹ Colunas apÃ³s normalizaÃ§Ã£o:', list(df.columns))

# 3ï¸âƒ£ Converter tipos
if 'ano' in df.columns:
    df['ano'] = pd.to_numeric(df['ano'], errors='coerce')
else:
    raise KeyError('Coluna "ano" nÃ£o encontrada apÃ³s normalizaÃ§Ã£o.')

if 'area_km' in df.columns:
    df['area_km'] = pd.to_numeric(df['area_km'], errors='coerce')
else:
    raise KeyError('Coluna "area_km" nÃ£o encontrada apÃ³s normalizaÃ§Ã£o.')

# 4ï¸âƒ£ Remover linhas invÃ¡lidas e filtrar anos
before = len(df)
df = df.dropna(subset=['ano', 'area_km', 'UF'])
df['ano'] = df['ano'].astype(int)
df['UF'] = df['UF'].astype(str).str.strip().str.upper()
df = df[(df['ano'] >= 2012) & (df['ano'] <= 2021)]
print(f'Linhas removidas por invÃ¡lidos/fora de intervalo: {before - len(df)}')

# 5ï¸âƒ£ Filtrar apenas UFs da AmazÃ´nia Legal
ufs_found = sorted(df['UF'].unique())
extra_ufs = [u for u in ufs_found if u not in AMAZONIA_LEGAL_UFS]
if extra_ufs:
    print('âš ï¸  Foram encontrados UFs fora da AmazÃ´nia Legal e serÃ£o removidos:', extra_ufs)
    df = df[df['UF'].isin(AMAZONIA_LEGAL_UFS)]

# 6ï¸âƒ£ Agregar total de Ã¡rea desmatada por estado e ano
df_estado = df.groupby(['UF', 'ano'], as_index=False)['area_km'].sum()

# 7ï¸âƒ£ Salvar versÃ£o agregada
df_estado.to_csv(output, index=False, encoding='utf-8-sig')
print('âœ… Base agregada por estado salva com sucesso em', output)